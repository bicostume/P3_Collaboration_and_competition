{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 2.0.9 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -6.65278625 -1.5        -0.          0.\n",
      "  6.83172083  6.         -0.          0.        ]\n",
      "Episode 100\tAverage Score: 0.00\tlast score: 0.00\n",
      "Episode 200\tAverage Score: 0.01\tlast score: 0.00\n",
      "Episode 300\tAverage Score: 0.01\tlast score: 0.09\n",
      "Episode 400\tAverage Score: 0.05\tlast score: 0.10\n",
      "Episode 500\tAverage Score: 0.04\tlast score: 0.00\n",
      "Episode 600\tAverage Score: 0.05\tlast score: 0.10\n",
      "Episode 700\tAverage Score: 0.04\tlast score: 0.10\n",
      "Episode 800\tAverage Score: 0.04\tlast score: 0.10\n",
      "Episode 900\tAverage Score: 0.04\tlast score: 0.00\n",
      "Episode 1000\tAverage Score: 0.05\tlast score: 0.10\n",
      "Episode 1100\tAverage Score: 0.05\tlast score: 0.09\n",
      "Episode 1200\tAverage Score: 0.09\tlast score: 0.10\n",
      "Episode 1300\tAverage Score: 0.09\tlast score: 0.10\n",
      "Episode 1400\tAverage Score: 0.09\tlast score: 0.09\n",
      "Episode 1500\tAverage Score: 0.08\tlast score: 0.00\n",
      "Episode 1600\tAverage Score: 0.07\tlast score: 0.09\n",
      "Episode 1700\tAverage Score: 0.10\tlast score: 0.00\n",
      "Episode 1800\tAverage Score: 0.16\tlast score: 0.10\n",
      "Episode 1900\tAverage Score: 0.17\tlast score: 0.10\n",
      "Episode 2000\tAverage Score: 0.15\tlast score: 0.10\n",
      "Episode 2100\tAverage Score: 0.31\tlast score: 0.10\n",
      "Episode 2200\tAverage Score: 0.43\tlast score: 0.20\n",
      "Episode 2300\tAverage Score: 0.22\tlast score: 0.10\n",
      "Episode 2400\tAverage Score: 0.18\tlast score: 0.10\n",
      "Episode 2500\tAverage Score: 0.43\tlast score: 1.40\n",
      "Episode 2508\tAverage Score: 0.51\tlast score: 2.60\n",
      "Environment solved in 2408 episodes!\tAverage Score: 0.51\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4b04d910f0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nagent = MADDPG(state_size, action_size, seed=10, a_check=None, c_check=None, gamma=0.995, tau=1e-3, add_noise=False, mu=0.,\\n                 theta=0.15, sigma=0.2, lr_actor=1e-4, lr_critic=4e-3,buffer_size=1e5, batch_size=200, update_every = 4,\\n                 low_action=-1, high_action=1, num_agents=2, warm_up=0, consecutive_learns=3, clip_critic_grad=0)\\n                 \\nEpisode 100\\tAverage Score: 0.03\\tlast score: 0.00\\nEpisode 200\\tAverage Score: 0.00\\tlast score: 0.00\\nEpisode 300\\tAverage Score: 0.02\\tlast score: 0.00\\nEpisode 400\\tAverage Score: 0.01\\tlast score: 0.00\\nEpisode 500\\tAverage Score: 0.01\\tlast score: 0.00\\nEpisode 600\\tAverage Score: 0.00\\tlast score: 0.00\\nEpisode 700\\tAverage Score: 0.01\\tlast score: 0.00\\nEpisode 800\\tAverage Score: 0.04\\tlast score: 0.00\\nEpisode 900\\tAverage Score: 0.01\\tlast score: 0.00\\nEpisode 1000\\tAverage Score: 0.07\\tlast score: 0.10\\nEpisode 1100\\tAverage Score: 0.09\\tlast score: 0.09\\nEpisode 1200\\tAverage Score: 0.08\\tlast score: 0.10\\nEpisode 1300\\tAverage Score: 0.08\\tlast score: 0.10\\nEpisode 1400\\tAverage Score: 0.11\\tlast score: 0.10\\nEpisode 1500\\tAverage Score: 0.10\\tlast score: 0.10\\nEpisode 1600\\tAverage Score: 0.12\\tlast score: 0.10\\nEpisode 1700\\tAverage Score: 0.08\\tlast score: 0.00\\nEpisode 1800\\tAverage Score: 0.08\\tlast score: 0.10\\nEpisode 1900\\tAverage Score: 0.11\\tlast score: 0.20\\nEpisode 2000\\tAverage Score: 0.08\\tlast score: 0.10\\nEpisode 2100\\tAverage Score: 0.23\\tlast score: 0.10\\nEpisode 2200\\tAverage Score: 0.14\\tlast score: 0.10\\nEpisode 2300\\tAverage Score: 0.10\\tlast score: 0.10\\nEpisode 2400\\tAverage Score: 0.24\\tlast score: 0.20\\nEpisode 2500\\tAverage Score: 0.31\\tlast score: 0.10\\nEpisode 2600\\tAverage Score: 0.29\\tlast score: 1.00\\nEpisode 2700\\tAverage Score: 0.54\\tlast score: 0.00\\nEpisode 2703\\tAverage Score: 0.51\\tlast score: 0.00\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from collections import deque\n",
    "from maddpg import MADDPG\n",
    "\n",
    "env = UnityEnvironment(file_name=\"/data/Tennis_Linux_NoVis/Tennis\")\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space\n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])\n",
    "'''\n",
    "count = 0\n",
    "import time\n",
    "for i in range(1, 6):                                      # play game for 5 episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment\n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        count += 1\n",
    "        #time.sleep(3)\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        #print(\"Agent 1:\")\n",
    "        #print(str(next_states[0]))\n",
    "        #print(\"Agent 2:\")\n",
    "        #print(str(next_states[1]))\n",
    "        #print()\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones) or count==10:                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Score (max over agents) from episode {}: {}'.format(i, np.max(scores)))\n",
    "\n",
    "env.close()\n",
    "'''\n",
    "\n",
    "# Create an agent, pass a desired size for the hiden layers.\n",
    "agent = MADDPG(state_size, action_size, seed=10, a_check=None, c_check=None, gamma=0.995, tau=1e-3, add_noise=False, mu=0.,\n",
    "                 theta=0.15, sigma=0.2, lr_actor=1e-4, lr_critic=3.5e-3,buffer_size=1e5, batch_size=200, update_every = 4,\n",
    "                 low_action=-1, high_action=1, num_agents=2, warm_up=0, consecutive_learns=3, clip_critic_grad=0)\n",
    "\n",
    "\n",
    "# Define dqn algorithm\n",
    "def maddpg(n_episodes=10000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "\n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []  # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start  # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes + 1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        agent.reset()\n",
    "        score = np.zeros(2)\n",
    "        while True:\n",
    "            actions = agent.act(states, random=False)\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states, rewards, dones = env_info.vector_observations, env_info.rewards, env_info.local_done\n",
    "\n",
    "            #next_state = agent.state_normalizer(next_state)\n",
    "            #reward = agent.reward_normalizer(reward)\n",
    "\n",
    "            agent.step(states, actions, rewards, next_states, dones, i_episode)\n",
    "            states = next_states\n",
    "            score += rewards\n",
    "            if np.any(dones):\n",
    "                break\n",
    "        episode_score = np.max(score)\n",
    "        scores_window.append(episode_score)  # save most recent score\n",
    "        scores.append(episode_score)  # save most recent score\n",
    "        eps = max(eps_end, eps_decay * eps)  # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\tlast score: {:.2f}'.format(i_episode, np.mean(scores_window), episode_score), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\nEpisode {}\\tAverage Score: {:.2f}\\tlast score: {:.2f}'.format(i_episode, np.mean(scores_window), episode_score), end=\"\")\n",
    "        if np.mean(scores_window) >= 0.5 and i_episode > 50:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode - 100,\n",
    "                                                                                         np.mean(scores_window)))\n",
    "            for i in range(0, num_agents):\n",
    "                torch.save(agent.agents[i].critic.state_dict(), 'my_critic_{}.pth'.format(i))\n",
    "                torch.save(agent.agents[i].actor.state_dict(), 'my_actor_{}.pth'.format(i))\n",
    "            break\n",
    "        # A small step in learning rate to allow for quicker convergence with above set parameters\n",
    "        #if i_episode == 1200:\n",
    "        #    agent.adjust_learning_rate(1200, 2E-5)\n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = maddpg()\n",
    "\n",
    "env.close()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()\n",
    "\n",
    "# Save scores\n",
    "with open('scores.txt', 'w') as f:\n",
    "    for item in scores:\n",
    "        f.write(\"%f\\n\" % item)\n",
    "\n",
    "\n",
    "'''\n",
    "agent = MADDPG(state_size, action_size, seed=10, a_check=None, c_check=None, gamma=0.995, tau=1e-3, add_noise=False, mu=0.,\n",
    "                 theta=0.15, sigma=0.2, lr_actor=1e-4, lr_critic=4e-3,buffer_size=1e5, batch_size=200, update_every = 4,\n",
    "                 low_action=-1, high_action=1, num_agents=2, warm_up=0, consecutive_learns=3, clip_critic_grad=0)\n",
    "                 \n",
    "Episode 100\tAverage Score: 0.03\tlast score: 0.00\n",
    "Episode 200\tAverage Score: 0.00\tlast score: 0.00\n",
    "Episode 300\tAverage Score: 0.02\tlast score: 0.00\n",
    "Episode 400\tAverage Score: 0.01\tlast score: 0.00\n",
    "Episode 500\tAverage Score: 0.01\tlast score: 0.00\n",
    "Episode 600\tAverage Score: 0.00\tlast score: 0.00\n",
    "Episode 700\tAverage Score: 0.01\tlast score: 0.00\n",
    "Episode 800\tAverage Score: 0.04\tlast score: 0.00\n",
    "Episode 900\tAverage Score: 0.01\tlast score: 0.00\n",
    "Episode 1000\tAverage Score: 0.07\tlast score: 0.10\n",
    "Episode 1100\tAverage Score: 0.09\tlast score: 0.09\n",
    "Episode 1200\tAverage Score: 0.08\tlast score: 0.10\n",
    "Episode 1300\tAverage Score: 0.08\tlast score: 0.10\n",
    "Episode 1400\tAverage Score: 0.11\tlast score: 0.10\n",
    "Episode 1500\tAverage Score: 0.10\tlast score: 0.10\n",
    "Episode 1600\tAverage Score: 0.12\tlast score: 0.10\n",
    "Episode 1700\tAverage Score: 0.08\tlast score: 0.00\n",
    "Episode 1800\tAverage Score: 0.08\tlast score: 0.10\n",
    "Episode 1900\tAverage Score: 0.11\tlast score: 0.20\n",
    "Episode 2000\tAverage Score: 0.08\tlast score: 0.10\n",
    "Episode 2100\tAverage Score: 0.23\tlast score: 0.10\n",
    "Episode 2200\tAverage Score: 0.14\tlast score: 0.10\n",
    "Episode 2300\tAverage Score: 0.10\tlast score: 0.10\n",
    "Episode 2400\tAverage Score: 0.24\tlast score: 0.20\n",
    "Episode 2500\tAverage Score: 0.31\tlast score: 0.10\n",
    "Episode 2600\tAverage Score: 0.29\tlast score: 1.00\n",
    "Episode 2700\tAverage Score: 0.54\tlast score: 0.00\n",
    "Episode 2703\tAverage Score: 0.51\tlast score: 0.00\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
